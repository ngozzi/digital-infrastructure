{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df53e87",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../functions/plot_style.py:21: MatplotlibDeprecationWarning: \n",
      "The createFontList function was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use FontManager.addfont instead.\n",
      "  font_list = font_manager.createFontList(font_files)\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "sys.path.append(\"../functions/\")\n",
    "from plot_style import plot_style\n",
    "colors = plot_style(\"../functions/fonts/\")\n",
    "from import_functions import *\n",
    "\n",
    "# first and last Monday\n",
    "start_date, end_date  = datetime(2020, 3, 2), datetime(2020, 12, 21)\n",
    "window = timedelta(days=7)\n",
    "dates = pd.to_datetime(np.arange(start_date, end_date + window, window))\n",
    "path_to_data = \"../../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5761be18-7b42-4564-9ba3-8bd70b0a3a47",
   "metadata": {},
   "source": [
    "# Create datasets for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9618eb93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataset_static(country, covs, popcol):\n",
    "\n",
    "    \"\"\"\n",
    "    Thi function create the dataset for the regression at the peak of mobility change\n",
    "    :param country: name of the country\n",
    "    :param covs: name of independent variables\n",
    "    :param popcol: population column\n",
    "    :return: dataframe of the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # import data\n",
    "    gadm2, maps, policy, epidata = import_gadm(country, path_to_data=path_to_data), import_range_maps(country, path_to_data=path_to_data), import_policy(country, path_to_data=path_to_data), import_epi(country, path_to_data=path_to_data)\n",
    "    #maps = maps.loc[maps.polygon_id.isin(gadm2.loc[gadm2.mean_mov.notnull()].GID_2.values)]\n",
    "\n",
    "    # keep gadm2 for which we have mobility data\n",
    "    gadm2 = gadm2.loc[gadm2.GID_2.isin(maps.polygon_id.unique())]\n",
    "\n",
    "    # mobility - keep only 2020\n",
    "    maps = maps.loc[(maps.ds >= datetime(2020, 1, 1)) & (maps.ds < datetime(2021, 1, 1))]\n",
    "\n",
    "    # mobility - remove weekends\n",
    "    maps = maps.loc[maps.ds.dt.dayofweek < 5].reset_index(drop=True)\n",
    "\n",
    "    # get maximum drawdown in mobility and stay at home\n",
    "    movs = {}\n",
    "    for date in dates:\n",
    "        # loc data in this week\n",
    "        maps_date = maps.loc[(maps.ds >= date) & (maps.ds < date + timedelta(days=5))]\n",
    "        epidata_date = epidata.loc[(epidata.date >= date) & (epidata.date < date + timedelta(days=7))]\n",
    "        \n",
    "        # iterate over municipalities\n",
    "        for gid_2 in maps_date.polygon_id.unique():\n",
    "            maps_date_gid2 = maps_date.loc[maps_date.polygon_id == gid_2]\n",
    "            epidata_date_gid2 = epidata_date.loc[epidata_date.GID_2 == gid_2]\n",
    "\n",
    "            # keep only municip. with full week data\n",
    "            if maps_date_gid2.shape[0] == 5:\n",
    "                if gid_2 not in movs.keys():\n",
    "                    movs[gid_2] = {\"cases\": [], \"movs\": [], \"stay\": []}\n",
    "                movs[gid_2][\"movs\"].append(-100 * maps_date_gid2.all_day_bing_tiles_visited_relative_change.mean())\n",
    "                movs[gid_2][\"stay\"].append(100 * maps_date_gid2.all_day_ratio_single_tile_users.mean())\n",
    "                movs[gid_2][\"cases\"].append(epidata_date_gid2.new_cases.sum())\n",
    "\n",
    "    data = {i: [] for i in np.concatenate(([\"max_movs\", \"cases\"], covs))}\n",
    "    data_stay = {i: [] for i in np.concatenate(([\"max_stay\", \"cases\"], covs))}\n",
    "\n",
    "    for gid_2 in movs.keys():\n",
    "        # keep only municipalities withh full 2020\n",
    "        if len(movs[gid_2][\"movs\"]) == len(dates):\n",
    "            idx = np.argmax(movs[gid_2][\"movs\"])\n",
    "            data[\"max_movs\"].append(movs[gid_2][\"movs\"][idx])\n",
    "            data[\"cases\"].append(movs[gid_2][\"cases\"][idx])\n",
    "            # add other features for this municip.\n",
    "            for cov in covs:\n",
    "                data[cov].append(gadm2.loc[gadm2.GID_2 == gid_2][cov].values[0])\n",
    "\n",
    "        if len(movs[gid_2][\"stay\"]) == len(dates):\n",
    "            idx = np.argmax(movs[gid_2][\"stay\"])\n",
    "            data_stay[\"max_stay\"].append(movs[gid_2][\"stay\"][idx])\n",
    "            data_stay[\"cases\"].append(movs[gid_2][\"cases\"][idx])\n",
    "            # add other features for this municip.\n",
    "            for cov in covs:\n",
    "                data_stay[cov].append(gadm2.loc[gadm2.GID_2 == gid_2][cov].values[0])\n",
    "\n",
    "    # standardize and preprocess\n",
    "    df_mov = pd.DataFrame(data=data)\n",
    "    df_mov_std = preprocess(df_mov, popcol=popcol)\n",
    "\n",
    "    df_stay = pd.DataFrame(data=data_stay)\n",
    "    df_stay_std = preprocess(df_stay, popcol=popcol)\n",
    "\n",
    "    return df_mov, df_stay, df_mov_std, df_stay_std\n",
    "\n",
    "\n",
    "def create_dataset_time(country, covs, popcol):\n",
    "\n",
    "    \"\"\"\n",
    "    Thi function create the dataset for the weekly regression\n",
    "    :param country: name of the country\n",
    "    :param covs: name of independent variables\n",
    "    :param popcol: population column\n",
    "    :return: dataframe of the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # import data\n",
    "    gadm2, maps, policy, epidata = import_gadm(country, path_to_data=path_to_data), import_range_maps(country, path_to_data=path_to_data), import_policy(country, path_to_data=path_to_data), import_epi(country, path_to_data=path_to_data)\n",
    "    #maps = maps.loc[maps.polygon_id.isin(gadm2.loc[gadm2.mean_mov.notnull()].GID_2.values)]\n",
    "\n",
    "    # keep gadm2 for which we have mobility data\n",
    "    gadm2 = gadm2.loc[gadm2.GID_2.isin(maps.polygon_id.unique())]\n",
    "\n",
    "    # mobility - keep only 2020\n",
    "    maps = maps.loc[(maps.ds >= datetime(2020, 1, 1)) & (maps.ds < datetime(2021, 1, 1))]\n",
    "\n",
    "    # mobility - remove weekends\n",
    "    maps = maps.loc[maps.ds.dt.dayofweek < 5].reset_index(drop=True)\n",
    "\n",
    "    # get weekly drawdown in mobility\n",
    "    movs = {}\n",
    "    for date in dates:\n",
    "        # loc data in this week\n",
    "        maps_date = maps.loc[(maps.ds >= date) & (maps.ds < date + timedelta(days=5))]\n",
    "        epidata_date = epidata.loc[(epidata.date >= date) & (epidata.date < date + timedelta(days=7))]\n",
    "\n",
    "        # iterate over municipalities\n",
    "        for gid_2 in maps_date.polygon_id.unique():\n",
    "            maps_date_gid2 = maps_date.loc[maps_date.polygon_id == gid_2]\n",
    "            epidata_date_gid2 = epidata_date.loc[epidata_date.GID_2 == gid_2]\n",
    "\n",
    "            # keep only municip. with full week data\n",
    "            if maps_date_gid2.shape[0] == 5:\n",
    "                if gid_2 not in movs.keys():\n",
    "                    movs[gid_2] = {\"cases\": [], \"movs\": [], \"stay\": []}\n",
    "                movs[gid_2][\"movs\"].append(-100 * maps_date_gid2.all_day_bing_tiles_visited_relative_change.mean())\n",
    "                movs[gid_2][\"stay\"].append(100 * maps_date_gid2.all_day_ratio_single_tile_users.mean())\n",
    "                movs[gid_2][\"cases\"].append(epidata_date_gid2.new_cases.sum())\n",
    "\n",
    "    data = {i: [] for i in np.concatenate(([\"max_movs\", \"max_stay\", \"cases\", \"week\"], covs))}\n",
    "\n",
    "    for gid_2 in movs.keys():\n",
    "        if len(movs[gid_2][\"movs\"]) == len(dates):\n",
    "            data[\"max_movs\"].extend(movs[gid_2][\"movs\"])\n",
    "            data[\"max_stay\"].extend(movs[gid_2][\"stay\"])\n",
    "            data[\"cases\"].extend(movs[gid_2][\"cases\"])\n",
    "            data[\"week\"].extend(range(len(dates)))\n",
    "            # add other features for this municip.\n",
    "            for cov in covs:\n",
    "                data[cov].extend(len(dates) * [gadm2.loc[gadm2.GID_2 == gid_2][cov].values[0]])\n",
    "\n",
    "    df = pd.DataFrame(data=data)\n",
    "    df_std = preprocess(df, popcol=popcol, avoid_cols=['week'])\n",
    "    return df, df_std\n",
    "\n",
    "\n",
    "def preprocess(df, popcol, cases_col=\"cases\", avoid_cols=[]):\n",
    "    \"\"\"\n",
    "    This function standardize the variables and perform some preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    df_r = df.copy()\n",
    "    # cases per 100k\n",
    "    df_r[cases_col] = 100000 * df_r[cases_col] / df_r[popcol]\n",
    "    #df_r['tests_unique_dev_fixed'] = df_r['tests_unique_dev_fixed'] / df_r[popcol]\n",
    "    df_r['tests_unique_dev_fixed'] = np.log(100 * df_r['tests_unique_dev_fixed'] / df_r[popcol])\n",
    "             \n",
    "    # log of popluation\n",
    "    df_r[popcol] = np.log(df_r[popcol])\n",
    "\n",
    "    for c in df_r.columns:\n",
    "        if c not in avoid_cols:\n",
    "            df_r[c] = (df_r[c] - df_r[c].mean()) / df_r[c].std()\n",
    "\n",
    "    # keep rows with no nans\n",
    "    df_r = df_r.loc[~df_r.isnull().any(axis=1)]\n",
    "    return df_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f5483-ed1e-410c-a7cc-6dc53a664255",
   "metadata": {},
   "source": [
    "- Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5817598",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py:131: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.4.0, the latest is 0.5.0.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py:131: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py:131: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "# colombia\n",
    "df_col_movs, df_col_stay, df_col_movs_std, df_col_stay_std = create_dataset_static(\"colombia\", [\"download_mbps_fixed\", \"rwi_weight\", \"gdp_per_capita\", \"popDANE\",\n",
    "                                                                                                \"pop_density\", \"pop60plus_ratio\", 'tests_unique_dev_fixed', \n",
    "                                                                                                \"internet_pen\", \"labor_formality_index\", \n",
    "                                                                                                \"primary_ratio\", \"secondary_ratio\", \"tertiary_ratio\"], popcol=\"popDANE\")\n",
    "df_col_movs.to_csv(\"./input-dfs-static/colombia_movs.csv\", index=False)\n",
    "df_col_stay.to_csv(\"./input-dfs-static/colombia_stay.csv\", index=False)\n",
    "df_col_movs_std.to_csv(\"./input-dfs-static/colombia_movs_std.csv\", index=False)\n",
    "df_col_stay_std.to_csv(\"./input-dfs-static/colombia_stay_std.csv\", index=False)\n",
    "\n",
    "\n",
    "df_ecu_movs, df_ecu_stay, df_ecu_movs_std, df_ecu_stay_std = create_dataset_static(\"ecuador\", [\"download_mbps_fixed\", \"rwi_weight\", \"pop2020\", \"pop_density\", \n",
    "                                                                                               \"pop60plus_ratio\", 'tests_unique_dev_fixed'], popcol=\"pop2020\")\n",
    "df_ecu_movs.to_csv(\"./input-dfs-static/ecuador_movs.csv\", index=False)\n",
    "df_ecu_stay.to_csv(\"./input-dfs-static/ecuador_stay.csv\", index=False)\n",
    "df_ecu_movs_std.to_csv(\"./input-dfs-static/ecuador_movs_std.csv\", index=False)\n",
    "df_ecu_stay_std.to_csv(\"./input-dfs-static/ecuador_stay_std.csv\", index=False)\n",
    "\n",
    "df_slv_movs, df_slv_stay, df_slv_movs_std, df_slv_stay_std = create_dataset_static(\"el-salvador\", [\"download_mbps_fixed\", \"rwi_weight\", \"gdp_per_capita\", \"pop2020\", \"pop_density\",\n",
    "                                                                                                   \"pop60plus_ratio\", 'tests_unique_dev_fixed'], popcol=\"pop2020\")\n",
    "df_slv_movs.to_csv(\"./input-dfs-static/el-salvador_movs.csv\", index=False)\n",
    "df_slv_stay.to_csv(\"./input-dfs-static/el-salvador_stay.csv\", index=False)\n",
    "df_slv_movs_std.to_csv(\"./input-dfs-static/el-salvador_movs_std.csv\", index=False)\n",
    "df_slv_stay_std.to_csv(\"./input-dfs-static/el-salvador_stay_std.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccbffe-c32b-4edd-a1cf-8f4d90332146",
   "metadata": {},
   "source": [
    "- Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cbf369b-16ca-4ca6-95c4-3027b4e0ce73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py:131: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py:131: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/pyproj/crs/crs.py:131: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "# colombia\n",
    "df_col_t, df_col_t_std = create_dataset_time(\"colombia\", [\"download_mbps_fixed\", \"rwi_weight\", \"gdp_per_capita\", \"popDANE\",\n",
    "                                                          \"pop_density\", \"pop60plus_ratio\", 'tests_unique_dev_fixed'], popcol=\"popDANE\")\n",
    "df_col_t.to_csv(\"./input-dfs-time/colombia_time.csv\", index=False)\n",
    "df_col_t_std.to_csv(\"./input-dfs-time/colombia_time_std.csv\", index=False)\n",
    "\n",
    "\n",
    "df_ecu_t, df_ecu_t_std = create_dataset_time(\"ecuador\", [\"download_mbps_fixed\", \"rwi_weight\", \"pop2020\", \"pop_density\",\n",
    "                                                         \"pop60plus_ratio\", 'tests_unique_dev_fixed'], popcol=\"pop2020\")\n",
    "df_ecu_t.to_csv(\"./input-dfs-time/ecuador_time.csv\", index=False)\n",
    "df_ecu_t_std.to_csv(\"./input-dfs-time/ecuador_time_std.csv\", index=False)\n",
    "\n",
    "df_slv_t, df_slv_t_std = create_dataset_time(\"el-salvador\", [\"download_mbps_fixed\", \"rwi_weight\", \"gdp_per_capita\", \"pop2020\", \n",
    "                                                             \"pop_density\", \"pop60plus_ratio\", 'tests_unique_dev_fixed'], popcol=\"pop2020\")\n",
    "\n",
    "df_slv_t.to_csv(\"./input-dfs-time/el-salvador_time.csv\", index=False)\n",
    "df_slv_t_std.to_csv(\"./input-dfs-time/el-salvador_time_std.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41e36b-6b15-4b38-82dd-0a510f7e4714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
